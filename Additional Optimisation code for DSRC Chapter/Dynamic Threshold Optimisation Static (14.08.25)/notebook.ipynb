{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cdist\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (Input, Conv1D, MaxPooling1D, \n",
    "                                     LSTM, Bidirectional, Dense, \n",
    "                                     Reshape, Dropout, Attention, \n",
    "                                     Concatenate, LayerNormalization)\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (precision_score, recall_score, \n",
    "                             f1_score, confusion_matrix)\n",
    "# import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.layers import GRU  # Add GRU import\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "\n",
    "def build_prediction_model(input_shape, output_steps, n_features):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    x = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(inputs)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "    x = Bidirectional(GRU(64, return_sequences=True))(x)\n",
    "\n",
    "    attention = Attention()([x, x])  # Self-attention\n",
    "    x = Concatenate()([x, attention])\n",
    "    x = LayerNormalization()(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "\n",
    "    x = GRU(64)(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(output_steps * n_features)(x)\n",
    "    outputs = Reshape((output_steps, n_features))(x)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.00093286), loss='mse', metrics=['mae', f1])\n",
    "    return model\n",
    "\n",
    "def load_trained_model(input_shape, output_steps, n_features):\n",
    "    model = build_prediction_model(input_shape, output_steps, n_features)\n",
    "    model.load_weights(\"gru_epoch_100_10_5.weights.h5\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        return true_positives / (possible_positives + K.epsilon())\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        return true_positives / (predicted_positives + K.epsilon())\n",
    "\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    return 2 * ((p * r) / (p + r + K.epsilon()))\n",
    "\n",
    "\n",
    "def calculate_entropy(data):\n",
    "    value_counts = np.bincount(data)\n",
    "    probabilities = value_counts / np.sum(value_counts)\n",
    "    probabilities = probabilities[probabilities > 0]\n",
    "    return -np.sum(probabilities * np.log2(probabilities))\n",
    "\n",
    "\n",
    "def dynthreshold(vectime, vecvalue):\n",
    "    time_stamps = np.array(vectime)\n",
    "    packets = np.array(vecvalue)\n",
    "    packets_int = np.round(packets).astype(int)\n",
    "    num_points = len(packets_int)\n",
    "\n",
    "    window_size = 15\n",
    "    entropy_values = np.array([\n",
    "        calculate_entropy(packets_int[max(0, i - window_size):i + 1]) for i in range(num_points)\n",
    "    ])\n",
    "    H_avg = np.mean(entropy_values)\n",
    "    sigma = np.std(entropy_values)\n",
    "    a = 0.2\n",
    "    T_1 = H_avg + a * sigma\n",
    "    return entropy_values, T_1, H_avg\n",
    "\n",
    "\n",
    "def hausdorff_distance(set1, set2):\n",
    "    dists = cdist(set1, set2, metric='euclidean')\n",
    "    forward = np.max(np.min(dists, axis=1))\n",
    "    backward = np.max(np.min(dists, axis=0))\n",
    "    return max(forward, backward)\n",
    "\n",
    "\n",
    "\n",
    "def plot_residuals(prediction, actual_continuation, feature_names, test_labels, time_sequence, look_back=18):\n",
    "    if actual_continuation is None:\n",
    "        print(\"Actual continuation is not available, cannot compute residuals.\")\n",
    "        return\n",
    "\n",
    "    def compute_ewma(series, alpha=0.2):\n",
    "        ewma = np.zeros_like(series)\n",
    "        ewma[0] = series[0]\n",
    "        for t in range(1, len(series)):\n",
    "            ewma[t] = alpha * series[t] + (1 - alpha) * ewma[t - 1]\n",
    "        return ewma\n",
    "\n",
    "    def rmse_windowed(y_true, y_pred, window):\n",
    "        return np.sqrt(np.mean((y_true - y_pred) ** 2, axis=1))\n",
    "\n",
    "    plot_times = time_sequence[look_back:look_back + len(prediction)]\n",
    "    plt.figure(figsize=(15, 6))\n",
    "\n",
    "    for i, feature in enumerate(feature_names):\n",
    "        plt.subplot(len(feature_names), 2, 2 * i + 1)\n",
    "\n",
    "        window_size = 5\n",
    "        rmse_series = np.array([\n",
    "            np.mean((actual_continuation[t:t+window_size, i] - prediction[t:t+window_size, i]) ** 2)\n",
    "            if t + window_size <= len(prediction) else 0\n",
    "            for t in range(len(prediction))\n",
    "        ])\n",
    "\n",
    "        smoothed_rmse = compute_ewma(rmse_series)\n",
    "        entropy_vals, T1, H_avg = dynthreshold(plot_times, smoothed_rmse)\n",
    "        anomalies = (entropy_vals > T1).astype(int)\n",
    "\n",
    "        for idx in np.where(anomalies == 1)[0]:\n",
    "            plt.axvspan(plot_times[idx] - 0.5, plot_times[idx] + 0.5, color='red', alpha=0.2)\n",
    "\n",
    "        true_anomalies_idx = np.where(test_labels[look_back:look_back + len(prediction)] == 1)[0]\n",
    "        for idx in true_anomalies_idx:\n",
    "            plt.axvspan(plot_times[idx] - 0.5, plot_times[idx] + 0.5, color='yellow', alpha=0.2)\n",
    "\n",
    "        y_true = test_labels[look_back:look_back + len(prediction)]\n",
    "        y_pred = anomalies\n",
    "\n",
    "        TP = np.sum((y_pred == 1) & (y_true == 1))\n",
    "        FN = np.sum((y_pred == 0) & (y_true == 1))\n",
    "        FP = np.sum((y_pred == 1) & (y_true == 0))\n",
    "        TN = np.sum((y_pred == 0) & (y_true == 0))\n",
    "\n",
    "        prob_detection = (TP / (TP + FN)) * 100 if (TP + FN) > 0 else 0.0\n",
    "        false_alarm_rate = (FP / (FP + TN)) * 100 if (FP + TN) > 0 else 0.0\n",
    "\n",
    "        print(f\"\\nMetrics for Feature: {feature}\")\n",
    "        print(f\"True Positives: {TP}\")\n",
    "        print(f\"False Positives: {FP}\")\n",
    "        print(f\"False Negatives: {FN}\")\n",
    "        print(f\"True Negatives: {TN}\")\n",
    "        print(f\"Probability of Detection (PD): {prob_detection:.2f}%\")\n",
    "        print(f\"False Alarm Rate (FAR): {false_alarm_rate:.2f}%\")\n",
    "\n",
    "        num_anomalies = np.sum(y_pred == 1)\n",
    "        total_points = len(y_pred)\n",
    "        anomaly_probability = (num_anomalies / total_points) if total_points > 0 else 0.0\n",
    "\n",
    "        print(f\"Anomaly Prob: {num_anomalies}/{total_points} ({anomaly_probability:.2f})\")\n",
    "\n",
    "        plt.plot(plot_times, rmse_series, label='MSE', color='blue', linestyle='dotted', alpha=0.5)\n",
    "        plt.plot(plot_times, smoothed_rmse, label='EWMA(MSE)', color='blue')\n",
    "        # plt.title(f'{feature} RMSE & EWMA - Anomaly Prob = {anomaly_probability:.2f}')\n",
    "        import matplotlib.patches as mpatches\n",
    "        pred_patch = mpatches.Patch(color='red', alpha=0.2, label='Predicted Anomalies')\n",
    "        true_patch = mpatches.Patch(color='yellow', alpha=0.2, label='True Anomalies')\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Error')\n",
    "        # plt.legend()\n",
    "        plt.legend(handles=[pred_patch, true_patch] + plt.gca().get_legend_handles_labels()[0])\n",
    "\n",
    "        plt.grid(True)\n",
    "\n",
    "        plt.subplot(len(feature_names), 2, 2 * i + 2)\n",
    "        plt.plot(plot_times, entropy_vals, label='Entropy', color='blue')\n",
    "        plt.axhline(y=T1, color='black', linestyle='--', label=f'Threshold = {T1:.2f}')\n",
    "        # plt.axhline(y=H_avg, color='green', linestyle=':', label=f'H_avg = {H_avg:.2f}')\n",
    "        # plt.title(f'{feature} Entropy of EWMA(RMSE)')\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Entropy')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('residuals_rmse_entropy_anomalies.png')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def test_single_sequence(model, input_sequence):\n",
    "    input_seq = np.expand_dims(input_sequence, axis=0)\n",
    "    prediction = model.predict(input_seq)[0]\n",
    "    return prediction\n",
    "\n",
    "\n",
    "def plot_test_results(input_sequence, prediction, actual_continuation, labels, feature_names, time_sequence):\n",
    "    look_back = input_sequence.shape[0]\n",
    "    look_forward = prediction.shape[0]\n",
    "    full_times = time_sequence[:look_back + look_forward]\n",
    "\n",
    "    plt.figure(figsize=(15, 6))\n",
    "\n",
    "    for i, feature in enumerate(feature_names):\n",
    "        plt.subplot(1, len(feature_names), i+1)\n",
    "\n",
    "        plt.plot(full_times[:look_back], input_sequence[:, i], 'b-o', label='Input')\n",
    "        plt.plot(full_times[look_back:look_back + look_forward], prediction[:, i], 'r--o', label='Prediction')\n",
    "\n",
    "        if actual_continuation is not None:\n",
    "            plt.plot(full_times[look_back:look_back + look_forward], actual_continuation[:, i], 'g-o', label='Actual')\n",
    "\n",
    "        input_anomalies = np.where(labels[:look_back] == 1)[0]\n",
    "        for idx in input_anomalies:\n",
    "            plt.axvspan(full_times[idx] - 0.5, full_times[idx] + 0.5, color='red', alpha=0.2)\n",
    "\n",
    "        continuation_anomalies = np.where(labels[look_back:look_back + look_forward] == 1)[0]\n",
    "        for idx in continuation_anomalies:\n",
    "            plt.axvspan(full_times[look_back + idx] - 0.5, full_times[look_back + idx] + 0.5, color='red', alpha=0.2)\n",
    "\n",
    "        plt.title(f'{feature} Prediction vs Actual')\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Value')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('prediction_vs_actual.png')\n",
    "    plt.show()\n",
    "\n",
    "def rolling_rmse(actual, predicted, window_size):\n",
    "    rmse = np.full_like(actual, np.nan, dtype=np.float64)\n",
    "    for i in range(window_size - 1, len(actual)):\n",
    "        rmse[i] = (mean_squared_error(actual[i - window_size + 1:i + 1],\n",
    "                                             predicted[i - window_size + 1:i + 1]))\n",
    "    return rmse\n",
    "\n",
    "def plot_overlay_with_rmse_residuals(time, actual, predicted, feature_name=\"Feature\", rmse_window=10, prediction_window=10):\n",
    "    residual_rmse = rolling_rmse(actual, predicted, rmse_window)\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8), sharex=True,\n",
    "                                   gridspec_kw={'height_ratios': [3, 1]})\n",
    "\n",
    "    # Plot Actual and Predicted\n",
    "    ax1.plot(time, actual, label='Actual', color='green', linewidth=2)\n",
    "    ax1.plot(time, predicted, label='Predicted', color='red',linestyle='dotted', alpha=0.7, linewidth=2)\n",
    "\n",
    "    # Shade prediction windows (gray)\n",
    "    for start in range(0, len(time), prediction_window):\n",
    "        end = min(start + prediction_window, len(time))\n",
    "        ax1.axvspan(time[start], time[end - 1], color='gray', alpha=0.1)\n",
    "\n",
    "    # Shade RMSE windows (light blue)\n",
    "    for start in range(rmse_window - 1, len(time), rmse_window):\n",
    "        end = min(start + 1, len(time))  # Single point RMSE computed at this time\n",
    "        ax2.axvspan(time[start - rmse_window + 1], time[start], color='lightblue', alpha=0.2)\n",
    "\n",
    "    ax1.set_ylabel(\"Value\")\n",
    "    ax1.legend()\n",
    "\n",
    "    # Plot RMSE Residual\n",
    "    ax2.plot(time, residual_rmse, label=f'Rolling MSE', color='blue', linestyle='--', linewidth=2)\n",
    "    ax2.set_xlabel(\"Time\")\n",
    "    ax2.set_ylabel(\"MSE\")\n",
    "    ax2.legend()\n",
    "\n",
    "    # Remove all borders and grid\n",
    "    for ax in [ax1, ax2]:\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_visible(False)\n",
    "        ax.tick_params(top=False, right=False)\n",
    "        ax.grid(False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('overlay_with_rmse_and_prediction_windows.png')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ---------------------- MAIN ----------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Load the CSV\n",
    "    df = pd.read_csv('All_LOS_DATA_decel_sequence_data_with_jerk.csv')\n",
    "\n",
    "    # Filter sequence if needed (e.g., LOS, DepartureTime, Iteration)\n",
    "    seq_df = df[(df['LOS'] == 'E') & (df['DepartureTime'] == 905) & (df['Iteration'] == 17)]  # <-- apply filters if necessary\n",
    "\n",
    "    # Extract features, labels, and time\n",
    "    time_sequence = seq_df['Time'].values\n",
    "    full_features = seq_df[['Speed','Acceleration','Jerk']].values\n",
    "    full_labels = seq_df['Label'].values.astype(int)\n",
    "    feature_names = ['Jerk'] #['Speed','Acceleration','Jerk']\n",
    "\n",
    "    # Verify shape consistency\n",
    "    if full_features.shape[1] != 3:\n",
    "        raise ValueError(f\"Expected 3 features, got {full_features.shape[1]}. Ensure you're using ['Speed', 'Acceleration', 'Jerk'].\")\n",
    "\n",
    "    # Parameters\n",
    "    look_back = 10\n",
    "    look_forward = 5\n",
    "    n_features = 3\n",
    "\n",
    "    model = load_trained_model(\n",
    "        input_shape=(look_back, n_features),\n",
    "        output_steps=look_forward,\n",
    "        n_features=n_features\n",
    "    )\n",
    "\n",
    "    # Initialize variables for storing predictions\n",
    "    all_predictions = []\n",
    "    all_actuals = []\n",
    "    all_times = []\n",
    "\n",
    "    # Loop through the sequence with sliding window\n",
    "    for i in range(0, len(full_features) - look_back - look_forward + 1, look_forward):\n",
    "        # Get current window\n",
    "        current_window = full_features[i:i+look_back]\n",
    "        actual_continuation = full_features[i+look_back:i+look_back+look_forward]\n",
    "        time_window = time_sequence[i+look_back:i+look_back+look_forward]\n",
    "        \n",
    "        # Make prediction\n",
    "        prediction = test_single_sequence(model, current_window)\n",
    "        \n",
    "        # Store results\n",
    "        all_predictions.append(prediction)\n",
    "        all_actuals.append(actual_continuation)\n",
    "        all_times.append(time_window)\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    all_predictions = np.concatenate(all_predictions)\n",
    "    all_actuals = np.concatenate(all_actuals)\n",
    "    all_times = np.concatenate(all_times)\n",
    "\n",
    "    # Create full predicted sequence (initial input + predictions)\n",
    "    predicted_sequence = np.vstack([full_features[:look_back], all_predictions])\n",
    "    actual_sequence = np.vstack([full_features[:look_back], all_actuals])\n",
    "    time_plot = np.concatenate([time_sequence[:look_back], all_times])\n",
    "\n",
    "    # ---- Plotting ----\n",
    "    plt.figure(figsize=(18, 6))\n",
    "\n",
    "    for i, feature in enumerate(feature_names):\n",
    "        plt.subplot(1, len(feature_names), i + 1)\n",
    "        \n",
    "        plt.plot(time_plot[:look_back], predicted_sequence[:look_back, i], 'b-o', label='Input', alpha=0.6)\n",
    "        plt.plot(time_plot[look_back:], predicted_sequence[look_back:, i], 'r--', label='Predicted')\n",
    "        plt.plot(time_plot[look_back:], actual_sequence[look_back:, i], 'g-', label='Actual')\n",
    "        \n",
    "        # Mark prediction windows\n",
    "        for j in range(look_back, len(time_plot), look_forward):\n",
    "            end = min(j + look_forward, len(time_plot))\n",
    "            plt.axvspan(time_plot[j], time_plot[end-1], color='gray', alpha=0.1)\n",
    "        \n",
    "        # plt.title(f'{feature}: Prediction vs Actual (Window size: {look_back}→{look_forward})')\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Value')\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('windowed_prediction_vs_actual.png')\n",
    "    plt.show()\n",
    "\n",
    "    # Slice matching labels\n",
    "    test_labels = full_labels[:predicted_sequence.shape[0]]\n",
    "\n",
    "    # Plot anomaly detection and print metrics\n",
    "    plot_residuals(\n",
    "        prediction=predicted_sequence[look_back:], \n",
    "        actual_continuation=actual_sequence[look_back:], \n",
    "        feature_names=feature_names,\n",
    "        test_labels=test_labels,\n",
    "        time_sequence=time_plot,\n",
    "        look_back=look_back\n",
    "    )\n",
    "\n",
    "    # Plot overlay with RMSE for each feature\n",
    "    for i, feature_name in enumerate(feature_names):\n",
    "        plot_overlay_with_rmse_residuals(\n",
    "            time=time_plot[look_back:], \n",
    "            actual=actual_sequence[look_back:, i], \n",
    "            predicted=predicted_sequence[look_back:, i],\n",
    "            feature_name=feature_name,\n",
    "            rmse_window=10,\n",
    "            prediction_window=look_forward\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test for Each LOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, LSTM, Bidirectional, Dense, Reshape, Dropout, Attention, Concatenate, LayerNormalization, GRU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, f1_score\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# ---------------------- Model Definition ----------------------\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        return true_positives / (possible_positives + K.epsilon())\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        return true_positives / (predicted_positives + K.epsilon())\n",
    "\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    return 2 * ((p * r) / (p + r + K.epsilon()))\n",
    "\n",
    "def build_prediction_model(input_shape, output_steps, n_features):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    x = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(inputs)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "    x = Bidirectional(GRU(64, return_sequences=True))(x)\n",
    "\n",
    "    attention = Attention()([x, x])  # Self-attention\n",
    "    x = Concatenate()([x, attention])\n",
    "    x = LayerNormalization()(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "\n",
    "    x = GRU(64)(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(output_steps * n_features)(x)\n",
    "    outputs = Reshape((output_steps, n_features))(x)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.00093286), loss='mse', metrics=['mae', f1])\n",
    "    return model\n",
    "\n",
    "def load_trained_model(input_shape, output_steps, n_features):\n",
    "    model = build_prediction_model(input_shape, output_steps, n_features)\n",
    "    model.load_weights(\"gru_epoch_100_10_5.weights.h5\")\n",
    "    return model\n",
    "\n",
    "# ---------------------- Helper Functions ----------------------\n",
    "\n",
    "def calculate_entropy(data):\n",
    "    value_counts = np.bincount(data)\n",
    "    probabilities = value_counts / np.sum(value_counts)\n",
    "    probabilities = probabilities[probabilities > 0]\n",
    "    return -np.sum(probabilities * np.log2(probabilities))\n",
    "\n",
    "def dynthreshold(vectime, vecvalue):\n",
    "    packets_int = np.round(vecvalue).astype(int)\n",
    "    num_points = len(packets_int)\n",
    "    window_size = 15\n",
    "    entropy_values = np.array([\n",
    "        calculate_entropy(packets_int[max(0, i - window_size):i + 1]) for i in range(num_points)\n",
    "    ])\n",
    "    H_avg = np.mean(entropy_values)\n",
    "    sigma = np.std(entropy_values)\n",
    "    a = 0.2\n",
    "    T_1 = H_avg + a * sigma\n",
    "    return entropy_values, T_1, H_avg\n",
    "\n",
    "def test_single_sequence(model, input_sequence):\n",
    "    input_seq = np.expand_dims(input_sequence, axis=0)\n",
    "    prediction = model.predict(input_seq)[0]\n",
    "    return prediction\n",
    "\n",
    "def compute_ewma(series, alpha=0.2):\n",
    "        ewma = np.zeros_like(series)\n",
    "        ewma[0] = series[0]\n",
    "        for t in range(1, len(series)):\n",
    "            ewma[t] = alpha * series[t] + (1 - alpha) * ewma[t - 1]\n",
    "        return ewma\n",
    "\n",
    "# ---------------------- Main Processing ----------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = pd.read_csv('Persistent_losA_Decel_sequence_data_with_jerk.csv')\n",
    "\n",
    "    look_back = 10\n",
    "    look_forward = 5\n",
    "    n_features = 3\n",
    "    feature_names = ['Speed', 'Acceleration', 'Jerk']\n",
    "    target_feature = 'Jerk'\n",
    "\n",
    "    model = load_trained_model(\n",
    "        input_shape=(look_back, n_features),\n",
    "        output_steps=look_forward,\n",
    "        n_features=n_features\n",
    "    )\n",
    "\n",
    "    sequences = df[['LOS', 'DepartureTime', 'Iteration']].drop_duplicates()\n",
    "    metrics_summary = []\n",
    "\n",
    "    for idx, row in sequences.iterrows():\n",
    "        start_time = time.time()\n",
    "\n",
    "        los = row['LOS']\n",
    "        departure_time = row['DepartureTime']\n",
    "        iteration = row['Iteration']\n",
    "        print(los, departure_time, iteration)\n",
    "        seq_df = df[(df['LOS'] == los) & (df['DepartureTime'] == departure_time) & (df['Iteration'] == iteration)]\n",
    "        if len(seq_df) < (look_back + look_forward):\n",
    "            continue\n",
    "\n",
    "        time_sequence = seq_df['Time'].values\n",
    "        full_features = seq_df[['Speed', 'Acceleration', 'Jerk']].values\n",
    "        full_labels = seq_df['Label'].values.astype(int)\n",
    "\n",
    "        all_predictions, all_actuals, all_times, all_labels = [], [], [], []\n",
    "\n",
    "        for i in range(0, len(full_features) - look_back - look_forward + 1, look_forward):\n",
    "            current_window = full_features[i:i+look_back]\n",
    "            actual_continuation = full_features[i+look_back:i+look_back+look_forward]\n",
    "            time_window = time_sequence[i+look_back:i+look_back+look_forward]\n",
    "            label_window = full_labels[i+look_back:i+look_back+look_forward]\n",
    "            prediction = test_single_sequence(model, current_window)\n",
    "            all_predictions.append(prediction)\n",
    "            all_actuals.append(actual_continuation)\n",
    "            all_times.append(time_window)\n",
    "            all_labels.append(label_window)\n",
    "\n",
    "        if not all_predictions:\n",
    "            continue\n",
    "\n",
    "        all_predictions = np.concatenate(all_predictions)\n",
    "        all_actuals = np.concatenate(all_actuals)\n",
    "        all_times = np.concatenate(all_times)\n",
    "        all_labels = np.concatenate(all_labels)\n",
    "\n",
    "        predicted_sequence = np.vstack([full_features[:look_back], all_predictions])\n",
    "        actual_sequence = np.vstack([full_features[:look_back], all_actuals])\n",
    "        time_plot = np.concatenate([time_sequence[:look_back], all_times])\n",
    "        test_labels = np.concatenate([full_labels[:look_back], all_labels])\n",
    "\n",
    "        feature_idx = feature_names.index(target_feature)\n",
    "        window_size = 10\n",
    "        mse_series = np.array([\n",
    "            np.mean((actual_sequence[t:t+window_size, feature_idx] - predicted_sequence[t:t+window_size, feature_idx]) ** 2)\n",
    "            if t + window_size <= len(predicted_sequence) else 0\n",
    "            for t in range(len(predicted_sequence))\n",
    "        ])\n",
    "\n",
    "        smoothed_mse = compute_ewma(mse_series[look_back:])\n",
    "        entropy_vals, T1, H_avg = dynthreshold(time_plot[look_back:], smoothed_mse)\n",
    "        anomalies = (entropy_vals > T1).astype(int)\n",
    "\n",
    "        y_true = test_labels[look_back:look_back+len(smoothed_mse)]\n",
    "        y_pred = anomalies\n",
    "\n",
    "        TP = np.sum((y_pred == 1) & (y_true == 1))\n",
    "        FP = np.sum((y_pred == 1) & (y_true == 0))\n",
    "        FN = np.sum((y_pred == 0) & (y_true == 1))\n",
    "        TN = np.sum((y_pred == 0) & (y_true == 0))\n",
    "\n",
    "        try:\n",
    "            auc = roc_auc_score(y_true, entropy_vals)\n",
    "        except ValueError:\n",
    "            auc = np.nan\n",
    "\n",
    "        f1_val = f1_score(y_true, y_pred, zero_division=0)\n",
    "        prob_detection = (TP / (TP + FN)) * 100 if (TP + FN) > 0 else 0.0\n",
    "        false_alarm_rate = (FP / (FP + TN)) * 100 if (FP + TN) > 0 else 0.0\n",
    "        anomaly_probability = (np.sum(y_pred == 1) / len(y_pred)) if len(y_pred) > 0 else 0.0\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        metrics_summary.append({\n",
    "            'LOS': los,\n",
    "            'DepartureTime': departure_time,\n",
    "            'Iteration': iteration,\n",
    "            'TP': TP,\n",
    "            'FP': FP,\n",
    "            'FN': FN,\n",
    "            'TN': TN,\n",
    "            'PD': prob_detection,\n",
    "            'FAR': false_alarm_rate,\n",
    "            'F1': f1_val,\n",
    "            'AUC': auc,\n",
    "            'Anomaly_Prob': anomaly_probability,\n",
    "            'Time_sec': end_time - start_time\n",
    "        })\n",
    "\n",
    "    if metrics_summary:\n",
    "        metrics_df = pd.DataFrame(metrics_summary)\n",
    "        numeric_cols = metrics_df.select_dtypes(include=np.number).columns\n",
    "        median_metrics = metrics_df[numeric_cols].median()\n",
    "        mean_metrics = metrics_df[numeric_cols].mean()\n",
    "\n",
    "        print(f\"\\n=== Summary Metrics for Feature: {target_feature} ===\")\n",
    "        print(f\"Window Configuration: look_back={look_back}, look_forward={look_forward}\")\n",
    "        print(f\"Total sequences analyzed: {len(metrics_df)}\")\n",
    "\n",
    "        print(\"\\nMedian Metrics:\")\n",
    "        print(median_metrics.round(4))\n",
    "\n",
    "        print(\"\\nMean Metrics:\")\n",
    "        print(mean_metrics.round(4))\n",
    "    else:\n",
    "        print(f\"No metrics collected for feature: {target_feature}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-16 08:48:16.022519: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-08-16 08:48:16.026698: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-08-16 08:48:16.039545: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1755330496.061193 3627903 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1755330496.067733 3627903 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1755330496.084665 3627903 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755330496.084681 3627903 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755330496.084684 3627903 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755330496.084686 3627903 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-08-16 08:48:16.090044: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "E0000 00:00:1755330502.829503 3627903 cuda_executor.cc:1228] INTERNAL: CUDA Runtime error: Failed call to cudaGetRuntimeVersion: Error loading CUDA libraries. GPU will not be used.: Error loading CUDA libraries. GPU will not be used.\n",
      "E0000 00:00:1755330502.830394 3627903 cuda_executor.cc:1228] INTERNAL: CUDA Runtime error: Failed call to cudaGetRuntimeVersion: Error loading CUDA libraries. GPU will not be used.: Error loading CUDA libraries. GPU will not be used.\n",
      "W0000 00:00:1755330502.835678 3627903 gpu_device.cc:2341] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "/share/home2/kamtams/jintel/lib/python3.9/site-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 36 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E 895 1\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 507ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\n",
      "=== Summary Metrics for Feature: Jerk ===\n",
      "Window Configuration: look_back=10, look_forward=5\n",
      "Total sequences analyzed: 1\n",
      "\n",
      "Median Metrics by LOS:\n",
      "     DepartureTime  Iteration   TP    FP   FN     TN   PD    FAR   F1  AUC  \\\n",
      "LOS                                                                          \n",
      "E            895.0        1.0  0.0  36.0  0.0  284.0  0.0  11.25  0.0  NaN   \n",
      "\n",
      "     Anomaly_Prob  Time_sec  \n",
      "LOS                          \n",
      "E          0.1125    5.1401  \n",
      "\n",
      "Mean Metrics by LOS:\n",
      "     DepartureTime  Iteration   TP    FP   FN     TN   PD    FAR   F1  AUC  \\\n",
      "LOS                                                                          \n",
      "E            895.0        1.0  0.0  36.0  0.0  284.0  0.0  11.25  0.0  NaN   \n",
      "\n",
      "     Anomaly_Prob  Time_sec  \n",
      "LOS                          \n",
      "E          0.1125    5.1401  \n",
      "E 895 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/home2/kamtams/jintel/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\n",
      "=== Summary Metrics for Feature: Jerk ===\n",
      "Window Configuration: look_back=10, look_forward=5\n",
      "Total sequences analyzed: 2\n",
      "\n",
      "Median Metrics by LOS:\n",
      "     DepartureTime  Iteration   TP    FP   FN     TN   PD    FAR   F1  AUC  \\\n",
      "LOS                                                                          \n",
      "E            895.0        1.5  0.0  18.0  0.0  292.0  0.0  5.625  0.0  NaN   \n",
      "\n",
      "     Anomaly_Prob  Time_sec  \n",
      "LOS                          \n",
      "E          0.0562    4.7698  \n",
      "\n",
      "Mean Metrics by LOS:\n",
      "     DepartureTime  Iteration   TP    FP   FN     TN   PD    FAR   F1  AUC  \\\n",
      "LOS                                                                          \n",
      "E            895.0        1.5  0.0  18.0  0.0  292.0  0.0  5.625  0.0  NaN   \n",
      "\n",
      "     Anomaly_Prob  Time_sec  \n",
      "LOS                          \n",
      "E          0.0562    4.7698  \n",
      "E 895 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/home2/kamtams/jintel/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\n",
      "=== Summary Metrics for Feature: Jerk ===\n",
      "Window Configuration: look_back=10, look_forward=5\n",
      "Total sequences analyzed: 3\n",
      "\n",
      "Median Metrics by LOS:\n",
      "     DepartureTime  Iteration   TP    FP   FN     TN   PD    FAR   F1  AUC  \\\n",
      "LOS                                                                          \n",
      "E            895.0        2.0  0.0  36.0  0.0  284.0  0.0  11.25  0.0  NaN   \n",
      "\n",
      "     Anomaly_Prob  Time_sec  \n",
      "LOS                          \n",
      "E          0.1125    4.3996  \n",
      "\n",
      "Mean Metrics by LOS:\n",
      "     DepartureTime  Iteration   TP       FP   FN        TN   PD    FAR   F1  \\\n",
      "LOS                                                                           \n",
      "E            895.0        2.0  0.0  26.6667  0.0  266.6667  0.0  9.391  0.0   \n",
      "\n",
      "     AUC  Anomaly_Prob  Time_sec  \n",
      "LOS                               \n",
      "E    NaN        0.0939     4.501  \n",
      "E 895 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/home2/kamtams/jintel/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\n",
      "=== Summary Metrics for Feature: Jerk ===\n",
      "Window Configuration: look_back=10, look_forward=5\n",
      "Total sequences analyzed: 4\n",
      "\n",
      "Median Metrics by LOS:\n",
      "     DepartureTime  Iteration   TP    FP   FN     TN   PD      FAR   F1  \\\n",
      "LOS                                                                       \n",
      "E            895.0        2.5  0.0  40.0  0.0  250.0  0.0  14.0865  0.0   \n",
      "\n",
      "        AUC  Anomaly_Prob  Time_sec  \n",
      "LOS                                  \n",
      "E    0.8307        0.1409    4.1815  \n",
      "\n",
      "Mean Metrics by LOS:\n",
      "     DepartureTime  Iteration    TP     FP   FN     TN    PD     FAR      F1  \\\n",
      "LOS                                                                            \n",
      "E            895.0        2.5  0.25  39.75  0.0  227.5  25.0  17.493  0.0062   \n",
      "\n",
      "        AUC  Anomaly_Prob  Time_sec  \n",
      "LOS                                  \n",
      "E    0.8307        0.1757    4.0773  \n",
      "E 895 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\n",
      "=== Summary Metrics for Feature: Jerk ===\n",
      "Window Configuration: look_back=10, look_forward=5\n",
      "Total sequences analyzed: 5\n",
      "\n",
      "Median Metrics by LOS:\n",
      "     DepartureTime  Iteration   TP    FP   FN     TN   PD      FAR   F1  \\\n",
      "LOS                                                                       \n",
      "E            895.0        3.0  0.0  43.0  0.0  216.0  0.0  16.9231  0.0   \n",
      "\n",
      "        AUC  Anomaly_Prob  Time_sec  \n",
      "LOS                                  \n",
      "E    0.7979        0.1692    3.9634  \n",
      "\n",
      "Mean Metrics by LOS:\n",
      "     DepartureTime  Iteration   TP    FP   FN     TN    PD      FAR      F1  \\\n",
      "LOS                                                                           \n",
      "E            895.0        3.0  1.2  40.4  0.0  200.4  40.0  20.3648  0.0427   \n",
      "\n",
      "        AUC  Anomaly_Prob  Time_sec  \n",
      "LOS                                  \n",
      "E    0.7979        0.2091     3.673  \n",
      "E 895 6\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\n",
      "=== Summary Metrics for Feature: Jerk ===\n",
      "Window Configuration: look_back=10, look_forward=5\n",
      "Total sequences analyzed: 6\n",
      "\n",
      "Median Metrics by LOS:\n",
      "     DepartureTime  Iteration   TP    FP   FN     TN   PD      FAR   F1  \\\n",
      "LOS                                                                       \n",
      "E            895.0        3.5  0.0  43.5  0.0  222.0  0.0  20.4615  0.0   \n",
      "\n",
      "        AUC  Anomaly_Prob  Time_sec  \n",
      "LOS                                  \n",
      "E    0.7979        0.2046    4.1815  \n",
      "\n",
      "Mean Metrics by LOS:\n",
      "     DepartureTime  Iteration   TP       FP   FN     TN       PD      FAR  \\\n",
      "LOS                                                                         \n",
      "E            895.0        3.5  1.0  45.6667  0.0  205.0  33.3333  20.9706   \n",
      "\n",
      "         F1     AUC  Anomaly_Prob  Time_sec  \n",
      "LOS                                          \n",
      "E    0.0356  0.7979        0.2143    3.8033  \n",
      "E 895 7\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/home2/kamtams/jintel/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, LSTM, Bidirectional, Dense, Reshape, Dropout, Attention, Concatenate, LayerNormalization, GRU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, f1_score\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# ---------------------- Model Definition ----------------------\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        return true_positives / (possible_positives + K.epsilon())\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        return true_positives / (predicted_positives + K.epsilon())\n",
    "\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    return 2 * ((p * r) / (p + r + K.epsilon()))\n",
    "\n",
    "def build_prediction_model(input_shape, output_steps, n_features):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    x = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(inputs)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "    x = Bidirectional(GRU(64, return_sequences=True))(x)\n",
    "\n",
    "    attention = Attention()([x, x])  # Self-attention\n",
    "    x = Concatenate()([x, attention])\n",
    "    x = LayerNormalization()(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "\n",
    "    x = GRU(64)(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(output_steps * n_features)(x)\n",
    "    outputs = Reshape((output_steps, n_features))(x)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.00093286), loss='mse', metrics=['mae', f1])\n",
    "    return model\n",
    "\n",
    "def load_trained_model(input_shape, output_steps, n_features):\n",
    "    model = build_prediction_model(input_shape, output_steps, n_features)\n",
    "    model.load_weights(\"gru_epoch_100_10_5.weights.h5\")\n",
    "    return model\n",
    "\n",
    "# ---------------------- Helper Functions ----------------------\n",
    "\n",
    "def calculate_entropy(data):\n",
    "    value_counts = np.bincount(data)\n",
    "    probabilities = value_counts / np.sum(value_counts)\n",
    "    probabilities = probabilities[probabilities > 0]\n",
    "    return -np.sum(probabilities * np.log2(probabilities))\n",
    "\n",
    "def dynthreshold(vectime, vecvalue):\n",
    "    packets_int = np.round(vecvalue).astype(int)\n",
    "    num_points = len(packets_int)\n",
    "    window_size = 20\n",
    "    entropy_values = np.array([\n",
    "        calculate_entropy(packets_int[max(0, i - window_size):i + 1]) for i in range(num_points)\n",
    "    ])\n",
    "    H_avg = np.mean(entropy_values)\n",
    "    sigma = np.std(entropy_values)\n",
    "    a = 0\n",
    "    T_1 = H_avg + a * sigma\n",
    "    return entropy_values, T_1, H_avg\n",
    "\n",
    "def test_single_sequence(model, input_sequence):\n",
    "    input_seq = np.expand_dims(input_sequence, axis=0)\n",
    "    prediction = model.predict(input_seq)[0]\n",
    "    return prediction\n",
    "\n",
    "def compute_ewma(series, alpha=0.2):\n",
    "    ewma = np.zeros_like(series)\n",
    "    ewma[0] = series[0]\n",
    "    for t in range(1, len(series)):\n",
    "        ewma[t] = alpha * series[t] + (1 - alpha) * ewma[t - 1]\n",
    "    return ewma\n",
    "\n",
    "# ---------------------- Main Processing ----------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = pd.read_csv('sequence_static_data_with_jerk.csv')\n",
    "\n",
    "    look_back = 10\n",
    "    look_forward = 5\n",
    "    n_features = 3\n",
    "    feature_names = ['Speed', 'Acceleration', 'Jerk']\n",
    "    target_feature = 'Jerk'\n",
    "\n",
    "    model = load_trained_model(\n",
    "        input_shape=(look_back, n_features),\n",
    "        output_steps=look_forward,\n",
    "        n_features=n_features\n",
    "    )\n",
    "\n",
    "    sequences = df[['LOS', 'DepartureTime', 'Iteration']].drop_duplicates()\n",
    "    metrics_summary = []\n",
    "\n",
    "    for idx, row in sequences.iterrows():\n",
    "        start_time = time.time()\n",
    "\n",
    "        los = 'E' #row['LOS']\n",
    "        departure_time = row['DepartureTime']\n",
    "        iteration = row['Iteration']\n",
    "        print(los, departure_time, iteration)\n",
    "        seq_df = df[(df['LOS'] == los) & (df['DepartureTime'] == departure_time) & (df['Iteration'] == iteration)]\n",
    "        if len(seq_df) < (look_back + look_forward):\n",
    "            continue\n",
    "\n",
    "        time_sequence = seq_df['Time'].values\n",
    "        full_features = seq_df[['Speed', 'Acceleration', 'Jerk']].values\n",
    "        full_labels = seq_df['Label'].values.astype(int)\n",
    "\n",
    "        all_predictions, all_actuals, all_times, all_labels = [], [], [], []\n",
    "\n",
    "        for i in range(0, len(full_features) - look_back - look_forward + 1, look_forward):\n",
    "            current_window = full_features[i:i+look_back]\n",
    "            actual_continuation = full_features[i+look_back:i+look_back+look_forward]\n",
    "            time_window = time_sequence[i+look_back:i+look_back+look_forward]\n",
    "            label_window = full_labels[i+look_back:i+look_back+look_forward]\n",
    "            prediction = test_single_sequence(model, current_window)\n",
    "            all_predictions.append(prediction)\n",
    "            all_actuals.append(actual_continuation)\n",
    "            all_times.append(time_window)\n",
    "            all_labels.append(label_window)\n",
    "\n",
    "        if not all_predictions:\n",
    "            continue\n",
    "\n",
    "        all_predictions = np.concatenate(all_predictions)\n",
    "        all_actuals = np.concatenate(all_actuals)\n",
    "        all_times = np.concatenate(all_times)\n",
    "        all_labels = np.concatenate(all_labels)\n",
    "\n",
    "        predicted_sequence = np.vstack([full_features[:look_back], all_predictions])\n",
    "        actual_sequence = np.vstack([full_features[:look_back], all_actuals])\n",
    "        time_plot = np.concatenate([time_sequence[:look_back], all_times])\n",
    "        test_labels = np.concatenate([full_labels[:look_back], all_labels])\n",
    "\n",
    "        # feature_idx = feature_names.index(target_feature)\n",
    "        # window_size = 10\n",
    "        # mse_series = np.array([\n",
    "        #     np.mean((actual_sequence[t:t+window_size, feature_idx] - predicted_sequence[t:t+window_size, feature_idx]) ** 2)\n",
    "        #     if t + window_size <= len(predicted_sequence) else 0\n",
    "        #     for t in range(len(predicted_sequence))\n",
    "        # ])\n",
    "\n",
    "        feature_idx = feature_names.index(target_feature)\n",
    "        delta = 1.0\n",
    "\n",
    "        # Extract the relevant feature from both sequences\n",
    "        y_true = actual_sequence[:, feature_idx]\n",
    "        y_pred = predicted_sequence[:, feature_idx]\n",
    "\n",
    "        # Compute Huber loss for the whole series\n",
    "        diff = y_true - y_pred\n",
    "        huber_series = np.where(\n",
    "            np.abs(diff) <= delta,\n",
    "            0.5 * diff ** 2,\n",
    "            delta * (np.abs(diff) - 0.5 * delta)\n",
    "        )\n",
    "\n",
    "        smoothed_mse = compute_ewma(huber_series[look_back:], 0.3)\n",
    "        entropy_vals, T1, H_avg = dynthreshold(time_plot[look_back:], smoothed_mse)\n",
    "        anomalies = (entropy_vals > T1).astype(int)\n",
    "\n",
    "        y_true = test_labels[look_back:look_back+len(smoothed_mse)]\n",
    "        y_pred = anomalies\n",
    "\n",
    "        TP = np.sum((y_pred == 1) & (y_true == 1))\n",
    "        FP = np.sum((y_pred == 1) & (y_true == 0))\n",
    "        FN = np.sum((y_pred == 0) & (y_true == 1))\n",
    "        TN = np.sum((y_pred == 0) & (y_true == 0))\n",
    "\n",
    "        try:\n",
    "            auc = roc_auc_score(y_true, entropy_vals)\n",
    "        except ValueError:\n",
    "            auc = np.nan\n",
    "\n",
    "        f1_val = f1_score(y_true, y_pred, zero_division=0)\n",
    "        prob_detection = (TP / (TP + FN)) * 100 if (TP + FN) > 0 else 0.0\n",
    "        false_alarm_rate = (FP / (FP + TN)) * 100 if (FP + TN) > 0 else 0.0\n",
    "        anomaly_probability = (np.sum(y_pred == 1) / len(y_pred)) if len(y_pred) > 0 else 0.0\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        metrics_summary.append({\n",
    "            'LOS': los,\n",
    "            'DepartureTime': departure_time,\n",
    "            'Iteration': iteration,\n",
    "            'TP': TP,\n",
    "            'FP': FP,\n",
    "            'FN': FN,\n",
    "            'TN': TN,\n",
    "            'PD': prob_detection,\n",
    "            'FAR': false_alarm_rate,\n",
    "            'F1': f1_val,\n",
    "            'AUC': auc,\n",
    "            'Anomaly_Prob': anomaly_probability,\n",
    "            'Time_sec': end_time - start_time\n",
    "        })\n",
    "\n",
    "        if metrics_summary:\n",
    "            metrics_df = pd.DataFrame(metrics_summary)\n",
    "            numeric_cols = metrics_df.select_dtypes(include=np.number).columns\n",
    "\n",
    "            print(f\"\\n=== Summary Metrics for Feature: {target_feature} ===\")\n",
    "            print(f\"Window Configuration: look_back={look_back}, look_forward={look_forward}\")\n",
    "            print(f\"Total sequences analyzed: {len(metrics_df)}\\n\")\n",
    "\n",
    "            grouped = metrics_df.groupby('LOS')[numeric_cols]\n",
    "\n",
    "            median_metrics = grouped.median().round(4)\n",
    "            mean_metrics = grouped.mean().round(4)\n",
    "\n",
    "            print(\"Median Metrics by LOS:\")\n",
    "            print(grouped.median().round(4))\n",
    "\n",
    "            print(\"\\nMean Metrics by LOS:\")\n",
    "            print(grouped.mean().round(4))\n",
    "\n",
    "            median_metrics.to_csv(f\"median_metrics_{target_feature}.csv\")\n",
    "            mean_metrics.to_csv(f\"mean_metrics_{target_feature}.csv\")\n",
    "        else:\n",
    "            print(f\"No metrics collected for feature: {target_feature}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Youden J index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-11 21:06:55.486646: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-08-11 21:06:55.490459: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-08-11 21:06:55.502359: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1754942815.522307  445520 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1754942815.528347  445520 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1754942815.543700  445520 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1754942815.543714  445520 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1754942815.543716  445520 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1754942815.543717  445520 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-08-11 21:06:55.549081: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "E0000 00:00:1754942825.418397  445520 cuda_executor.cc:1228] INTERNAL: CUDA Runtime error: Failed call to cudaGetRuntimeVersion: Error loading CUDA libraries. GPU will not be used.: Error loading CUDA libraries. GPU will not be used.\n",
      "E0000 00:00:1754942825.419536  445520 cuda_executor.cc:1228] INTERNAL: CUDA Runtime error: Failed call to cudaGetRuntimeVersion: Error loading CUDA libraries. GPU will not be used.: Error loading CUDA libraries. GPU will not be used.\n",
      "W0000 00:00:1754942825.426227  445520 gpu_device.cc:2341] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "/share/home2/kamtams/jintel/lib/python3.9/site-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 36 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing LOS A, Departure 895, Iteration 1\n",
      "Processing LOS A, Departure 895, Iteration 2\n",
      "Processing LOS A, Departure 895, Iteration 3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cdist\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (Input, Conv1D, MaxPooling1D, \n",
    "                                     GRU, Bidirectional, Dense, \n",
    "                                     Reshape, Dropout, Attention, \n",
    "                                     Concatenate, LayerNormalization)\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# --- Plotting functions ---\n",
    "def plot_optimization_results(agg_results, top_n=10):\n",
    "    top = agg_results.sort_values(by='Youden_index', ascending=False).head(top_n)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    scatter = plt.scatter(top['a'], top['window_size'],\n",
    "                          c=top['Youden_index'], cmap='viridis', s=100, edgecolor='k')\n",
    "    plt.colorbar(scatter, label='Youden Index')\n",
    "    for i, row in top.iterrows():\n",
    "        plt.text(row['a'], row['window_size'], row['loss_func'], fontsize=9,\n",
    "                 ha='center', va='center', color='white', weight='bold')\n",
    "    plt.title(f'Top {top_n} Hyperparameter Combinations by Youden Index')\n",
    "    plt.xlabel('Threshold Scaling (a)')\n",
    "    plt.ylabel('Window Size')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_pd_vs_far(agg_results):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    scatter = plt.scatter(agg_results['FAR'], agg_results['PD'],\n",
    "                          c=agg_results['Youden_index'], cmap='plasma', s=80, edgecolor='k')\n",
    "    plt.colorbar(scatter, label='Youden Index')\n",
    "    plt.title('PD vs FAR for Hyperparameter Combinations')\n",
    "    plt.xlabel('False Alarm Rate (FAR)')\n",
    "    plt.ylabel('Probability of Detection (PD)')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# --- Model definition ---\n",
    "def build_prediction_model(input_shape, output_steps, n_features):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(inputs)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "    x = Bidirectional(GRU(64, return_sequences=True))(x)\n",
    "    attention = Attention()([x, x])\n",
    "    x = Concatenate()([x, attention])\n",
    "    x = LayerNormalization()(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = GRU(64)(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(output_steps * n_features)(x)\n",
    "    outputs = Reshape((output_steps, n_features))(x)\n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.00093286), loss='mse', metrics=['mae', f1])\n",
    "    return model\n",
    "\n",
    "def load_trained_model(input_shape, output_steps, n_features):\n",
    "    model = build_prediction_model(input_shape, output_steps, n_features)\n",
    "    model.load_weights(\"gru_epoch_100_10_5.weights.h5\")  # make sure this file exists\n",
    "    return model\n",
    "\n",
    "# --- Custom metric ---\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        return true_positives / (possible_positives + K.epsilon())\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        return true_positives / (predicted_positives + K.epsilon())\n",
    "\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    return 2 * ((p * r) / (p + r + K.epsilon()))\n",
    "\n",
    "# --- Utility functions ---\n",
    "def calculate_entropy(data):\n",
    "    value_counts = np.bincount(data)\n",
    "    probabilities = value_counts / np.sum(value_counts)\n",
    "    probabilities = probabilities[probabilities > 0]\n",
    "    return -np.sum(probabilities * np.log2(probabilities))\n",
    "\n",
    "def hausdorff_distance(set1, set2):\n",
    "    dists = cdist(set1, set2, metric='euclidean')\n",
    "    forward = np.max(np.min(dists, axis=1))\n",
    "    backward = np.max(np.min(dists, axis=0))\n",
    "    return max(forward, backward)\n",
    "\n",
    "def compute_residuals(y_true, y_pred, loss_type='rmse'):\n",
    "    if loss_type == 'rmse':\n",
    "        return np.sqrt(np.mean((y_true - y_pred) ** 2, axis=1))\n",
    "    elif loss_type == 'mse':\n",
    "        return np.mean((y_true - y_pred) ** 2, axis=1)\n",
    "    elif loss_type == 'mae':\n",
    "        return np.mean(np.abs(y_true - y_pred), axis=1)\n",
    "    elif loss_type == 'huber':\n",
    "        delta = 1.0\n",
    "        diff = y_true - y_pred\n",
    "        return np.mean(np.where(np.abs(diff) <= delta,\n",
    "                                0.5 * diff ** 2,\n",
    "                                delta * (np.abs(diff) - 0.5 * delta)), axis=1)\n",
    "    elif loss_type == 'hausdorff':\n",
    "        return np.array([\n",
    "            hausdorff_distance(np.expand_dims(y_true[i], axis=0), np.expand_dims(y_pred[i], axis=0))\n",
    "            for i in range(len(y_true))\n",
    "        ])\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown loss type: {loss_type}\")\n",
    "\n",
    "def compute_ewma(series, alpha=0.2):\n",
    "    ewma = np.zeros_like(series)\n",
    "    ewma[0] = series[0]\n",
    "    for t in range(1, len(series)):\n",
    "        ewma[t] = alpha * series[t] + (1 - alpha) * ewma[t - 1]\n",
    "    return ewma\n",
    "\n",
    "# --- Core optimization function ---\n",
    "def optimize_anomaly_detection_on_all_sequences(df, model, feature_names=['Speed', 'Acceleration', 'Jerk'], look_back=10, look_forward=5):\n",
    "    a_range = np.linspace(-2, 2, int((2 - (-2)) / 0.1) + 1)\n",
    "    window_sizes = [5,10,15,20]\n",
    "    loss_functions = ['rmse', 'mse', 'mae', 'huber', 'hausdorff']\n",
    "    alphas = np.linspace(0, 1, int((1 - 0) / 0.1) + 1)\n",
    "    results = []\n",
    "\n",
    "    # for los in ['A', 'B', 'C', 'D', 'E']:\n",
    "    #     los_df = df[df['LOS'] == los]\n",
    "    #     unique_sequences = los_df[['DepartureTime', 'Iteration']].drop_duplicates()\n",
    "    #     sampled_sequences = unique_sequences.sample(n=min(100, len(unique_sequences)), random_state=5)\n",
    "\n",
    "    #     for _, row in sampled_sequences.iterrows():\n",
    "    #         dep_time = row['DepartureTime']\n",
    "    #         iteration = row['Iteration']\n",
    "    #         seq_df = los_df[(los_df['DepartureTime'] == dep_time) & (los_df['Iteration'] == iteration)]\n",
    "\n",
    "    for los in ['A', 'B', 'C', 'D', 'E']:\n",
    "            for dep_time in range(895, 906):\n",
    "                for iteration in range(1, 31):\n",
    "                    seq_df = df[(df['LOS'] == los) &\n",
    "                                (df['DepartureTime'] == dep_time) &\n",
    "                                (df['Iteration'] == iteration)]\n",
    "\n",
    "                    if len(seq_df) < look_back + look_forward:\n",
    "                        continue\n",
    "\n",
    "                    print(f\"Processing LOS {los}, Departure {dep_time}, Iteration {iteration}\")\n",
    "                    time_sequence = seq_df['Time'].values\n",
    "                    full_features = seq_df[feature_names].values\n",
    "                    full_labels = seq_df['Label'].values.astype(int)\n",
    "\n",
    "                    all_predictions = []\n",
    "                    all_actuals = []\n",
    "                    all_times = []\n",
    "\n",
    "                    for i in range(0, len(full_features) - look_back - look_forward + 1, look_forward):\n",
    "                        current_window = full_features[i:i+look_back]\n",
    "                        actual_continuation = full_features[i+look_back:i+look_back+look_forward]\n",
    "                        time_window = time_sequence[i+look_back:i+look_back+look_forward]\n",
    "                        prediction = model.predict(np.expand_dims(current_window, axis=0), verbose=0)[0]\n",
    "                        all_predictions.append(prediction)\n",
    "                        all_actuals.append(actual_continuation)\n",
    "                        all_times.append(time_window)\n",
    "\n",
    "                    if not all_predictions:\n",
    "                        continue\n",
    "\n",
    "                    prediction = np.concatenate(all_predictions)\n",
    "                    actual = np.concatenate(all_actuals)\n",
    "\n",
    "                    # ✅ Focus only on Jerk (column index 2)\n",
    "                    jerk_index = feature_names.index('Jerk')\n",
    "                    prediction = prediction[:, jerk_index].reshape(-1, 1)\n",
    "                    actual = actual[:, jerk_index].reshape(-1, 1)\n",
    "\n",
    "                    test_labels = full_labels[:look_back + len(prediction)]\n",
    "\n",
    "                    for loss in loss_functions:\n",
    "                        for window_size in window_sizes:\n",
    "                            for alpha in alphas:\n",
    "                                residual_series = compute_residuals(actual, prediction, loss_type=loss)\n",
    "                                smoothed = compute_ewma(residual_series, alpha)\n",
    "\n",
    "                                for a in a_range:\n",
    "                                    entropy_vals = np.array([\n",
    "                                        calculate_entropy(np.round(smoothed[max(0, i - window_size):i + 1]).astype(int))\n",
    "                                        for i in range(len(smoothed))\n",
    "                                    ])\n",
    "\n",
    "                                    H_avg = np.mean(entropy_vals)\n",
    "                                    sigma = np.std(entropy_vals)\n",
    "                                    T1 = H_avg + a * sigma\n",
    "                                    anomalies = (entropy_vals > T1).astype(int)\n",
    "\n",
    "                                    y_true = test_labels[look_back:look_back + len(prediction)]\n",
    "                                    y_pred = anomalies[:len(y_true)]\n",
    "\n",
    "                                    TP = np.sum((y_pred == 1) & (y_true == 1))\n",
    "                                    FN = np.sum((y_pred == 0) & (y_true == 1))\n",
    "                                    FP = np.sum((y_pred == 1) & (y_true == 0))\n",
    "                                    TN = np.sum((y_pred == 0) & (y_true == 0))\n",
    "\n",
    "                                    PD = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "                                    FAR = FP / (FP + TN) if (FP + TN) > 0 else 0\n",
    "                                    YI = PD - FAR\n",
    "\n",
    "                                    results.append({\n",
    "                                        'LOS': los,\n",
    "                                        'DepartureTime': dep_time,\n",
    "                                        'Iteration': iteration,\n",
    "                                        'a': a,\n",
    "                                        'window_size': window_size,\n",
    "                                        'loss_func': loss,\n",
    "                                        'alpha': alpha,\n",
    "                                        'PD': PD,\n",
    "                                        'FAR': FAR,\n",
    "                                        'Youden_index': YI\n",
    "                                    })\n",
    "\n",
    "    # existing code (means)\n",
    "    df_results = pd.DataFrame(results)\n",
    "    df_results2 = pd.DataFrame(results)\n",
    "\n",
    "    agg_results = (\n",
    "        df_results\n",
    "        .groupby(['a', 'window_size', 'loss_func', 'alpha'])\n",
    "        .agg(PD_mean=('PD', 'mean'), FAR_mean=('FAR', 'mean'))\n",
    "        .reset_index()\n",
    "    )\n",
    "    agg_results['Youden_index'] = agg_results['PD_mean'] - agg_results['FAR_mean']\n",
    "    \n",
    "    # plot_optimization_results(agg_results, top_n=10)\n",
    "    # plot_pd_vs_far(agg_results)\n",
    "    \n",
    "    print(\"\\nTop 10 global parameter combinations (across all sequences, by mean Youden):\")\n",
    "    top10 = agg_results.sort_values(by='Youden_index', ascending=False).head(10)\n",
    "    print(top10)\n",
    "    \n",
    "    top100 = agg_results.sort_values(by='Youden_index', ascending=False)\n",
    "    top100.to_csv(\"top_global_parameter_combinations.csv\", index=False)\n",
    "    \n",
    "    # NEW: medians into a separate CSV\n",
    "    agg_results_median = (\n",
    "        df_results2\n",
    "        .groupby(['a', 'window_size', 'loss_func', 'alpha'])\n",
    "        .agg(PD_median=('PD', 'median'), FAR_median=('FAR', 'median'))\n",
    "        .reset_index()\n",
    "    )\n",
    "    agg_results_median['Youden_index_median'] = (\n",
    "        agg_results_median['PD_median'] - agg_results_median['FAR_median']\n",
    "    )\n",
    "    \n",
    "    # (Optional) Inspect top 10 by median Youden index\n",
    "    print(\"\\nTop 10 global parameter combinations (by median Youden):\")\n",
    "    print(\n",
    "        agg_results_median\n",
    "        .sort_values(by='Youden_index_median', ascending=False)\n",
    "        .head(10)\n",
    "    )\n",
    "    \n",
    "    # Save full median-ranked table\n",
    "    top_median = agg_results_median.sort_values(by='Youden_index_median', ascending=False)\n",
    "    top_median.to_csv(\"top_global_parameter_combinations_median.csv\", index=False)\n",
    "\n",
    "    return top10, agg_results\n",
    "\n",
    "# --- MAIN ---\n",
    "if __name__ == \"__main__\":\n",
    "    look_back = 10\n",
    "    look_forward = 5\n",
    "    feature_names = ['Speed', 'Acceleration', 'Jerk']\n",
    "    n_features = len(feature_names)\n",
    "\n",
    "    model = load_trained_model(\n",
    "        input_shape=(look_back, n_features),\n",
    "        output_steps=look_forward,\n",
    "        n_features=n_features\n",
    "    )\n",
    "\n",
    "    df = pd.read_csv('sequence_static_data_with_jerk.csv')\n",
    "\n",
    "    top10_results, agg_results = optimize_anomaly_detection_on_all_sequences(\n",
    "        df=df,\n",
    "        model=model,\n",
    "        feature_names=feature_names,\n",
    "        look_back=look_back,\n",
    "        look_forward=look_forward\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.  -1.9 -1.8 -1.7 -1.6 -1.5 -1.4 -1.3 -1.2 -1.1 -1.  -0.9 -0.8 -0.7\n",
      " -0.6 -0.5 -0.4 -0.3 -0.2 -0.1  0.   0.1  0.2  0.3  0.4  0.5  0.6  0.7\n",
      "  0.8  0.9  1.   1.1  1.2  1.3  1.4  1.5  1.6  1.7  1.8  1.9  2. ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "values = np.linspace(-2, 2, int((2 - (-2)) / 0.1) + 1)\n",
    "print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 global parameter combinations (across all sequences):\n",
      "               a  window_size  loss_func        PD       FAR  Youden_index\n",
      "38  2.000000e-01           15        mse  0.912430  0.184784      0.727646\n",
      "43  3.000000e-01           15        mse  0.902059  0.174698      0.727361\n",
      "48  4.000000e-01           15        mse  0.890466  0.163353      0.727113\n",
      "33  1.000000e-01           15        mse  0.920942  0.194086      0.726856\n",
      "28 -1.110223e-16           15        mse  0.928544  0.202304      0.726240\n",
      "23 -1.000000e-01           15        mse  0.934310  0.208984      0.725326\n",
      "18 -2.000000e-01           15        mse  0.938310  0.214767      0.723543\n",
      "35  2.000000e-01           15  hausdorff  0.901920  0.179775      0.722146\n",
      "39  2.000000e-01           15       rmse  0.901920  0.179775      0.722146\n",
      "37  2.000000e-01           15        mae  0.901920  0.179775      0.722146\n",
      "45  4.000000e-01           15  hausdorff  0.886683  0.164704      0.721979\n",
      "47  4.000000e-01           15        mae  0.886683  0.164704      0.721979\n",
      "49  4.000000e-01           15       rmse  0.886683  0.164704      0.721979\n",
      "27 -1.110223e-16           15        mae  0.914304  0.192341      0.721963\n",
      "29 -1.110223e-16           15       rmse  0.914304  0.192341      0.721963\n",
      "25 -1.110223e-16           15  hausdorff  0.914304  0.192341      0.721963\n",
      "42  3.000000e-01           15        mae  0.895382  0.173445      0.721937\n",
      "44  3.000000e-01           15       rmse  0.895382  0.173445      0.721937\n",
      "40  3.000000e-01           15  hausdorff  0.895382  0.173445      0.721937\n",
      "30  1.000000e-01           15  hausdorff  0.908054  0.186676      0.721378\n"
     ]
    }
   ],
   "source": [
    "top100 = agg_results.sort_values(by='Youden_index', ascending=False).head(20)\n",
    "\n",
    "print(\"\\nTop 10 global parameter combinations (across all sequences):\")\n",
    "print(top100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>window_size</th>\n",
       "      <th>loss_func</th>\n",
       "      <th>PD</th>\n",
       "      <th>FAR</th>\n",
       "      <th>Youden_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2.000000e-01</td>\n",
       "      <td>15</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.912430</td>\n",
       "      <td>0.184784</td>\n",
       "      <td>0.727646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>3.000000e-01</td>\n",
       "      <td>15</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.902059</td>\n",
       "      <td>0.174698</td>\n",
       "      <td>0.727361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>4.000000e-01</td>\n",
       "      <td>15</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.890466</td>\n",
       "      <td>0.163353</td>\n",
       "      <td>0.727113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>15</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.920942</td>\n",
       "      <td>0.194086</td>\n",
       "      <td>0.726856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-1.110223e-16</td>\n",
       "      <td>15</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.928544</td>\n",
       "      <td>0.202304</td>\n",
       "      <td>0.726240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-1.000000e-01</td>\n",
       "      <td>15</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.934310</td>\n",
       "      <td>0.208984</td>\n",
       "      <td>0.725326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-2.000000e-01</td>\n",
       "      <td>15</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.938310</td>\n",
       "      <td>0.214767</td>\n",
       "      <td>0.723543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2.000000e-01</td>\n",
       "      <td>15</td>\n",
       "      <td>hausdorff</td>\n",
       "      <td>0.901920</td>\n",
       "      <td>0.179775</td>\n",
       "      <td>0.722146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2.000000e-01</td>\n",
       "      <td>15</td>\n",
       "      <td>rmse</td>\n",
       "      <td>0.901920</td>\n",
       "      <td>0.179775</td>\n",
       "      <td>0.722146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2.000000e-01</td>\n",
       "      <td>15</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.901920</td>\n",
       "      <td>0.179775</td>\n",
       "      <td>0.722146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>4.000000e-01</td>\n",
       "      <td>15</td>\n",
       "      <td>hausdorff</td>\n",
       "      <td>0.886683</td>\n",
       "      <td>0.164704</td>\n",
       "      <td>0.721979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>4.000000e-01</td>\n",
       "      <td>15</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.886683</td>\n",
       "      <td>0.164704</td>\n",
       "      <td>0.721979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>4.000000e-01</td>\n",
       "      <td>15</td>\n",
       "      <td>rmse</td>\n",
       "      <td>0.886683</td>\n",
       "      <td>0.164704</td>\n",
       "      <td>0.721979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-1.110223e-16</td>\n",
       "      <td>15</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.914304</td>\n",
       "      <td>0.192341</td>\n",
       "      <td>0.721963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-1.110223e-16</td>\n",
       "      <td>15</td>\n",
       "      <td>rmse</td>\n",
       "      <td>0.914304</td>\n",
       "      <td>0.192341</td>\n",
       "      <td>0.721963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-1.110223e-16</td>\n",
       "      <td>15</td>\n",
       "      <td>hausdorff</td>\n",
       "      <td>0.914304</td>\n",
       "      <td>0.192341</td>\n",
       "      <td>0.721963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>3.000000e-01</td>\n",
       "      <td>15</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.895382</td>\n",
       "      <td>0.173445</td>\n",
       "      <td>0.721937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>3.000000e-01</td>\n",
       "      <td>15</td>\n",
       "      <td>rmse</td>\n",
       "      <td>0.895382</td>\n",
       "      <td>0.173445</td>\n",
       "      <td>0.721937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>3.000000e-01</td>\n",
       "      <td>15</td>\n",
       "      <td>hausdorff</td>\n",
       "      <td>0.895382</td>\n",
       "      <td>0.173445</td>\n",
       "      <td>0.721937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>15</td>\n",
       "      <td>hausdorff</td>\n",
       "      <td>0.908054</td>\n",
       "      <td>0.186676</td>\n",
       "      <td>0.721378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>15</td>\n",
       "      <td>rmse</td>\n",
       "      <td>0.908054</td>\n",
       "      <td>0.186676</td>\n",
       "      <td>0.721378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>15</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.908054</td>\n",
       "      <td>0.186676</td>\n",
       "      <td>0.721378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-1.000000e-01</td>\n",
       "      <td>15</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.918753</td>\n",
       "      <td>0.197940</td>\n",
       "      <td>0.720812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-1.000000e-01</td>\n",
       "      <td>15</td>\n",
       "      <td>rmse</td>\n",
       "      <td>0.918753</td>\n",
       "      <td>0.197940</td>\n",
       "      <td>0.720812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-1.000000e-01</td>\n",
       "      <td>15</td>\n",
       "      <td>hausdorff</td>\n",
       "      <td>0.918753</td>\n",
       "      <td>0.197940</td>\n",
       "      <td>0.720812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-2.000000e-01</td>\n",
       "      <td>15</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.923082</td>\n",
       "      <td>0.202780</td>\n",
       "      <td>0.720302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-2.000000e-01</td>\n",
       "      <td>15</td>\n",
       "      <td>hausdorff</td>\n",
       "      <td>0.923082</td>\n",
       "      <td>0.202780</td>\n",
       "      <td>0.720302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-2.000000e-01</td>\n",
       "      <td>15</td>\n",
       "      <td>rmse</td>\n",
       "      <td>0.923082</td>\n",
       "      <td>0.202780</td>\n",
       "      <td>0.720302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-3.000000e-01</td>\n",
       "      <td>15</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.945794</td>\n",
       "      <td>0.266182</td>\n",
       "      <td>0.679611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-3.000000e-01</td>\n",
       "      <td>15</td>\n",
       "      <td>rmse</td>\n",
       "      <td>0.930177</td>\n",
       "      <td>0.251100</td>\n",
       "      <td>0.679077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-3.000000e-01</td>\n",
       "      <td>15</td>\n",
       "      <td>hausdorff</td>\n",
       "      <td>0.930177</td>\n",
       "      <td>0.251100</td>\n",
       "      <td>0.679077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-3.000000e-01</td>\n",
       "      <td>15</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.930177</td>\n",
       "      <td>0.251100</td>\n",
       "      <td>0.679077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-4.000000e-01</td>\n",
       "      <td>15</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.955257</td>\n",
       "      <td>0.350365</td>\n",
       "      <td>0.604892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-4.000000e-01</td>\n",
       "      <td>15</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.945746</td>\n",
       "      <td>0.351038</td>\n",
       "      <td>0.594708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-4.000000e-01</td>\n",
       "      <td>15</td>\n",
       "      <td>hausdorff</td>\n",
       "      <td>0.945746</td>\n",
       "      <td>0.351038</td>\n",
       "      <td>0.594708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-4.000000e-01</td>\n",
       "      <td>15</td>\n",
       "      <td>rmse</td>\n",
       "      <td>0.945746</td>\n",
       "      <td>0.351038</td>\n",
       "      <td>0.594708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>15</td>\n",
       "      <td>hausdorff</td>\n",
       "      <td>0.958671</td>\n",
       "      <td>0.487217</td>\n",
       "      <td>0.471453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>15</td>\n",
       "      <td>rmse</td>\n",
       "      <td>0.958671</td>\n",
       "      <td>0.487217</td>\n",
       "      <td>0.471453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>15</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.958671</td>\n",
       "      <td>0.487217</td>\n",
       "      <td>0.471453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>15</td>\n",
       "      <td>mse</td>\n",
       "      <td>0.965748</td>\n",
       "      <td>0.495466</td>\n",
       "      <td>0.470282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-1.000000e-01</td>\n",
       "      <td>15</td>\n",
       "      <td>huber</td>\n",
       "      <td>0.355046</td>\n",
       "      <td>0.057235</td>\n",
       "      <td>0.297811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-2.000000e-01</td>\n",
       "      <td>15</td>\n",
       "      <td>huber</td>\n",
       "      <td>0.356373</td>\n",
       "      <td>0.059066</td>\n",
       "      <td>0.297307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-1.110223e-16</td>\n",
       "      <td>15</td>\n",
       "      <td>huber</td>\n",
       "      <td>0.354180</td>\n",
       "      <td>0.056959</td>\n",
       "      <td>0.297221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>15</td>\n",
       "      <td>huber</td>\n",
       "      <td>0.353401</td>\n",
       "      <td>0.056700</td>\n",
       "      <td>0.296701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2.000000e-01</td>\n",
       "      <td>15</td>\n",
       "      <td>huber</td>\n",
       "      <td>0.349909</td>\n",
       "      <td>0.056370</td>\n",
       "      <td>0.293539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>3.000000e-01</td>\n",
       "      <td>15</td>\n",
       "      <td>huber</td>\n",
       "      <td>0.347080</td>\n",
       "      <td>0.055881</td>\n",
       "      <td>0.291199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-3.000000e-01</td>\n",
       "      <td>15</td>\n",
       "      <td>huber</td>\n",
       "      <td>0.403835</td>\n",
       "      <td>0.114582</td>\n",
       "      <td>0.289253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>4.000000e-01</td>\n",
       "      <td>15</td>\n",
       "      <td>huber</td>\n",
       "      <td>0.342636</td>\n",
       "      <td>0.055171</td>\n",
       "      <td>0.287465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-4.000000e-01</td>\n",
       "      <td>15</td>\n",
       "      <td>huber</td>\n",
       "      <td>0.494619</td>\n",
       "      <td>0.272996</td>\n",
       "      <td>0.221623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>15</td>\n",
       "      <td>huber</td>\n",
       "      <td>0.565102</td>\n",
       "      <td>0.479506</td>\n",
       "      <td>0.085596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               a  window_size  loss_func        PD       FAR  Youden_index\n",
       "38  2.000000e-01           15        mse  0.912430  0.184784      0.727646\n",
       "43  3.000000e-01           15        mse  0.902059  0.174698      0.727361\n",
       "48  4.000000e-01           15        mse  0.890466  0.163353      0.727113\n",
       "33  1.000000e-01           15        mse  0.920942  0.194086      0.726856\n",
       "28 -1.110223e-16           15        mse  0.928544  0.202304      0.726240\n",
       "23 -1.000000e-01           15        mse  0.934310  0.208984      0.725326\n",
       "18 -2.000000e-01           15        mse  0.938310  0.214767      0.723543\n",
       "35  2.000000e-01           15  hausdorff  0.901920  0.179775      0.722146\n",
       "39  2.000000e-01           15       rmse  0.901920  0.179775      0.722146\n",
       "37  2.000000e-01           15        mae  0.901920  0.179775      0.722146\n",
       "45  4.000000e-01           15  hausdorff  0.886683  0.164704      0.721979\n",
       "47  4.000000e-01           15        mae  0.886683  0.164704      0.721979\n",
       "49  4.000000e-01           15       rmse  0.886683  0.164704      0.721979\n",
       "27 -1.110223e-16           15        mae  0.914304  0.192341      0.721963\n",
       "29 -1.110223e-16           15       rmse  0.914304  0.192341      0.721963\n",
       "25 -1.110223e-16           15  hausdorff  0.914304  0.192341      0.721963\n",
       "42  3.000000e-01           15        mae  0.895382  0.173445      0.721937\n",
       "44  3.000000e-01           15       rmse  0.895382  0.173445      0.721937\n",
       "40  3.000000e-01           15  hausdorff  0.895382  0.173445      0.721937\n",
       "30  1.000000e-01           15  hausdorff  0.908054  0.186676      0.721378\n",
       "34  1.000000e-01           15       rmse  0.908054  0.186676      0.721378\n",
       "32  1.000000e-01           15        mae  0.908054  0.186676      0.721378\n",
       "22 -1.000000e-01           15        mae  0.918753  0.197940      0.720812\n",
       "24 -1.000000e-01           15       rmse  0.918753  0.197940      0.720812\n",
       "20 -1.000000e-01           15  hausdorff  0.918753  0.197940      0.720812\n",
       "17 -2.000000e-01           15        mae  0.923082  0.202780      0.720302\n",
       "15 -2.000000e-01           15  hausdorff  0.923082  0.202780      0.720302\n",
       "19 -2.000000e-01           15       rmse  0.923082  0.202780      0.720302\n",
       "13 -3.000000e-01           15        mse  0.945794  0.266182      0.679611\n",
       "14 -3.000000e-01           15       rmse  0.930177  0.251100      0.679077\n",
       "10 -3.000000e-01           15  hausdorff  0.930177  0.251100      0.679077\n",
       "12 -3.000000e-01           15        mae  0.930177  0.251100      0.679077\n",
       "8  -4.000000e-01           15        mse  0.955257  0.350365      0.604892\n",
       "7  -4.000000e-01           15        mae  0.945746  0.351038      0.594708\n",
       "5  -4.000000e-01           15  hausdorff  0.945746  0.351038      0.594708\n",
       "9  -4.000000e-01           15       rmse  0.945746  0.351038      0.594708\n",
       "0  -5.000000e-01           15  hausdorff  0.958671  0.487217      0.471453\n",
       "4  -5.000000e-01           15       rmse  0.958671  0.487217      0.471453\n",
       "2  -5.000000e-01           15        mae  0.958671  0.487217      0.471453\n",
       "3  -5.000000e-01           15        mse  0.965748  0.495466      0.470282\n",
       "21 -1.000000e-01           15      huber  0.355046  0.057235      0.297811\n",
       "16 -2.000000e-01           15      huber  0.356373  0.059066      0.297307\n",
       "26 -1.110223e-16           15      huber  0.354180  0.056959      0.297221\n",
       "31  1.000000e-01           15      huber  0.353401  0.056700      0.296701\n",
       "36  2.000000e-01           15      huber  0.349909  0.056370      0.293539\n",
       "41  3.000000e-01           15      huber  0.347080  0.055881      0.291199\n",
       "11 -3.000000e-01           15      huber  0.403835  0.114582      0.289253\n",
       "46  4.000000e-01           15      huber  0.342636  0.055171      0.287465\n",
       "6  -4.000000e-01           15      huber  0.494619  0.272996      0.221623\n",
       "1  -5.000000e-01           15      huber  0.565102  0.479506      0.085596"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-import required libraries after environment reset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Save the top 20 combinations to a CSV file\n",
    "top100 = agg_results.sort_values(by='Youden_index', ascending=False)\n",
    "top100.to_csv(\"top_20_global_parameter_combinations.csv\", index=False)\n",
    "\n",
    "top100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def plot_pd_vs_far_with_optimal_point(agg_results):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    \n",
    "    # Scatter plot\n",
    "    scatter = plt.scatter(\n",
    "        agg_results['FAR'], agg_results['PD'],\n",
    "        c=agg_results['Youden_index'], cmap='viridis', s=80, edgecolor='k'\n",
    "    )\n",
    "    plt.colorbar(scatter, label='Youden Index')\n",
    "\n",
    "    # Add diagonal reference line (line of no discrimination)\n",
    "    x = np.linspace(0, 1, 100)\n",
    "    plt.plot(x, x, color='gray', linestyle='--', label='No Discrimination Line (PD=FAR)')\n",
    "\n",
    "    # Compute perpendicular distance from each point to the line y = x\n",
    "    distances = np.abs(agg_results['PD'] - agg_results['FAR']) / np.sqrt(2)\n",
    "    max_idx = distances.idxmax()\n",
    "    optimal_row = agg_results.loc[max_idx]\n",
    "\n",
    "    # Plot the optimal point and its perpendicular line to the diagonal\n",
    "    optimal_far = optimal_row['FAR']\n",
    "    optimal_pd = optimal_row['PD']\n",
    "    plt.plot([optimal_far, optimal_pd], [optimal_pd, optimal_far], 'r--', label='Max Perpendicular Distance')\n",
    "    plt.scatter(optimal_far, optimal_pd, color='red', s=100, zorder=5, label=f\"Optimal (a={np.round(optimal_row['a'],3)})\")\n",
    "\n",
    "    # Labels and grid\n",
    "    plt.xlabel('False Alarm Rate (FAR)')\n",
    "    plt.ylabel('Probability of Detection (PD)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_pd_vs_far_with_optimal_point(agg_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jintel",
   "language": "python",
   "name": "jintel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
