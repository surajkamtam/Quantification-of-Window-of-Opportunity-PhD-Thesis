{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Path to your CSV file\n",
        "# csv_file_path = '/content/December.csv'\n",
        "# output_csv_file_path = '/content/December60Sresults.csv'\n",
        "\n",
        "csv_file_path = 'Jan.csv'\n",
        "output_csv_file_path = 'Janresults.csv'\n",
        "\n",
        "try:\n",
        "    # Read the CSV file into a DataFrame, using on_bad_lines='skip' to skip bad lines\n",
        "    df = pd.read_csv(csv_file_path, delimiter=',', quotechar='\"', skiprows=3, on_bad_lines='skip')\n",
        "\n",
        "    # Columns to delete\n",
        "    columns_to_delete = [' Day Type ID', ' Total Carriageway Flow', ' Quality Index', ' Network Link Id', ' NTIS Model Version']\n",
        "\n",
        "    # Drop the specified columns\n",
        "    df = df.drop(columns=columns_to_delete)\n",
        "\n",
        "    df[' Total Flow vehicles less than 5.2m'] = df[' Total Flow vehicles less than 5.2m'].interpolate(method='linear')\n",
        "    df[' Total Flow vehicles 5.21m - 6.6m'] = df[' Total Flow vehicles 5.21m - 6.6m'].interpolate(method='linear')\n",
        "    df[' Total Flow vehicles 6.61m - 11.6m'] = df[' Total Flow vehicles 6.61m - 11.6m'].interpolate(method='linear')\n",
        "    df[' Total Flow vehicles above 11.6m'] = df[' Total Flow vehicles above 11.6m'].interpolate(method='linear')\n",
        "    df[' Speed Value'] = df[' Speed Value'].interpolate(method='linear')\n",
        "\n",
        "\n",
        "    # Perform the multiplications and renaming\n",
        "    df['Category 1'] = df[' Total Flow vehicles less than 5.2m'] * 1\n",
        "    df['Category 2'] = df[' Total Flow vehicles 5.21m - 6.6m'] * 1.5\n",
        "    df['Category 3'] = df[' Total Flow vehicles 6.61m - 11.6m'] * 2\n",
        "    df['Category 4'] = df[' Total Flow vehicles above 11.6m'] * 2.3\n",
        "    df['Avg Speed in mph'] = df[' Speed Value'] * 0.621371\n",
        "\n",
        "    # Drop the original columns that have been transformed\n",
        "    df = df.drop(columns=[' Total Flow vehicles less than 5.2m',\n",
        "                          ' Total Flow vehicles 5.21m - 6.6m',\n",
        "                          ' Total Flow vehicles 6.61m - 11.6m',\n",
        "                          ' Total Flow vehicles above 11.6m',\n",
        "                          ' Speed Value'])\n",
        "\n",
        "    # Add the new column for total number of vehicles\n",
        "    df['Total number of vehicles'] = df['Category 1'] + df['Category 2'] + df['Category 3'] + df['Category 4']\n",
        "\n",
        "    # Group the data in 4-row chunks and sum the values\n",
        "    def aggregate_chunk(chunk):\n",
        "        return pd.Series({\n",
        "            'Local Date': chunk['Local Date'].iloc[0],\n",
        "            ' Local Time': chunk[' Local Time'].iloc[0][:2] + ':00:00',\n",
        "            'Category 1': chunk['Category 1'].sum(),\n",
        "            'Category 2': chunk['Category 2'].sum(),\n",
        "            'Category 3': chunk['Category 3'].sum(),\n",
        "            'Category 4': chunk['Category 4'].sum(),\n",
        "            'Avg Speed in mph': chunk['Avg Speed in mph'].mean(),  # Assuming average speed is desired\n",
        "            'Total number of vehicles': chunk['Total number of vehicles'].sum()\n",
        "        })\n",
        "\n",
        "    # Apply the aggregation function to each 4-row chunk\n",
        "    aggregated_df = df.groupby(df.index // 4).apply(aggregate_chunk).reset_index(drop=True)\n",
        "\n",
        "    # Round the Total number of vehicles to the nearest integer\n",
        "    aggregated_df['Total number of vehicles'] = aggregated_df['Total number of vehicles'].round()\n",
        "    aggregated_df['LOS'] = aggregated_df['Total number of vehicles'] / aggregated_df['Avg Speed in mph']\n",
        "\n",
        "    # Categorize LOS values\n",
        "    los_bins = [0, 11, 18, 26, 35, 40, float('inf')]\n",
        "    los_labels = ['A', 'B', 'C', 'D', 'E', 'F']\n",
        "    aggregated_df['LOS Category'] = pd.cut(aggregated_df['LOS'], bins=los_bins, labels=los_labels, right=False)\n",
        "\n",
        "    df_pivot = aggregated_df.pivot(index='Local Date', columns=' Local Time', values=['LOS', 'LOS Category'])\n",
        "\n",
        "    # Count values for each LOS category\n",
        "    los_category_counts = aggregated_df['LOS Category'].value_counts().reindex(los_labels)\n",
        "\n",
        "    # Save the aggregated DataFrame to a new CSV file\n",
        "    df_pivot.to_csv(output_csv_file_path, index=True)\n",
        "\n",
        "    print(f\"Aggregated data saved to '{output_csv_file_path}'\")\n",
        "    print(\"LOS Category Counts:\")\n",
        "    print(los_category_counts)\n",
        "\n",
        "    pa=los_category_counts['A']/(los_category_counts['A']+los_category_counts['B']+los_category_counts['C']+los_category_counts['D']+los_category_counts['E']+los_category_counts['F'])\n",
        "    pb=los_category_counts['B']/(los_category_counts['A']+los_category_counts['B']+los_category_counts['C']+los_category_counts['D']+los_category_counts['E']+los_category_counts['F'])\n",
        "    pc=los_category_counts['C']/(los_category_counts['A']+los_category_counts['B']+los_category_counts['C']+los_category_counts['D']+los_category_counts['E']+los_category_counts['F'])\n",
        "    pd=los_category_counts['D']/(los_category_counts['A']+los_category_counts['B']+los_category_counts['C']+los_category_counts['D']+los_category_counts['E']+los_category_counts['F'])\n",
        "    pe=los_category_counts['E']/(los_category_counts['A']+los_category_counts['B']+los_category_counts['C']+los_category_counts['D']+los_category_counts['E']+los_category_counts['F'])\n",
        "    pf=los_category_counts['F']/(los_category_counts['A']+los_category_counts['B']+los_category_counts['C']+los_category_counts['D']+los_category_counts['E']+los_category_counts['F'])\n",
        "    print(pa,pb,pc,pd,pe,pf)\n",
        "except pd.errors.ParserError as e:\n",
        "    print(f'ParserError: {e}')\n",
        "except Exception as e:\n",
        "    print(f'Error: {e}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PML5-x81FtKh",
        "outputId": "2ca79634-bb9b-4510-9a73-3dce2693ecb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aggregated data saved to 'Janresults.csv'\n",
            "LOS Category Counts:\n",
            "LOS Category\n",
            "A    459\n",
            "B    236\n",
            "C     49\n",
            "D      0\n",
            "E      0\n",
            "F      0\n",
            "Name: count, dtype: int64\n",
            "0.6169354838709677 0.3172043010752688 0.06586021505376344 0.0 0.0 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Code for interpolating the existing data\n",
        "import pandas as pd\n",
        "\n",
        "# Path to your CSV file\n",
        "# csv_file_path = '/content/December.csv'\n",
        "# output_csv_file_path = '/content/December60Sresults.csv'\n",
        "\n",
        "csv_file_path = 'Jan.csv'\n",
        "output_csv_file_path = 'Janresults.csv'\n",
        "\n",
        "# Read the CSV file into a DataFrame, using on_bad_lines='skip' to skip bad lines\n",
        "df = pd.read_csv(csv_file_path, delimiter=',', quotechar='\"', skiprows=3, on_bad_lines='skip')\n",
        "\n",
        "# Columns to delete\n",
        "columns_to_delete = [' Day Type ID',' Quality Index', ' Network Link Id', ' NTIS Model Version']\n",
        "\n",
        "# Drop the specified columns\n",
        "df = df.drop(columns=columns_to_delete)\n",
        "\n",
        "df[' Total Carriageway Flow'] = df[' Total Carriageway Flow'].interpolate(method='linear')\n",
        "df[' Total Flow vehicles less than 5.2m'] = df[' Total Flow vehicles less than 5.2m'].interpolate(method='linear')\n",
        "df[' Total Flow vehicles 5.21m - 6.6m'] = df[' Total Flow vehicles 5.21m - 6.6m'].interpolate(method='linear')\n",
        "df[' Total Flow vehicles 6.61m - 11.6m'] = df[' Total Flow vehicles 6.61m - 11.6m'].interpolate(method='linear')\n",
        "df[' Total Flow vehicles above 11.6m'] = df[' Total Flow vehicles above 11.6m'].interpolate(method='linear')\n",
        "df[' Speed Value'] = df[' Speed Value'].interpolate(method='linear')\n",
        "\n",
        "\n",
        "df.to_csv(output_csv_file_path, index=True) #Corrected line\n",
        "\n"
      ],
      "metadata": {
        "id": "kZq9FjwReVPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duY7PZpfHN_L",
        "outputId": "389c4e01-af1f-4e17-9e57-2b3d991d83ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6169354838709677 0.3172043010752688 0.06586021505376344 0.0 0.0 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Path to your CSV file\n",
        "# csv_file_path = '/content/October.csv'\n",
        "# output_csv_file_path = '/content/Octresults.csv'\n",
        "\n",
        "csv_file_path = 'Jan.csv'\n",
        "output_csv_file_path = 'Janresults.csv'\n",
        "try:\n",
        "    # Read the CSV file into a DataFrame, using on_bad_lines='skip' to skip bad lines\n",
        "    df = pd.read_csv(csv_file_path, delimiter=',', quotechar='\"', skiprows=4, on_bad_lines='skip')\n",
        "\n",
        "    # Columns to delete\n",
        "    columns_to_delete = ['Day Type ID', 'Total Carriageway Flow', 'Quality Index', 'Network Link Id', 'NTIS Model Version']\n",
        "\n",
        "    # Drop the specified columns\n",
        "    df = df.drop(columns=columns_to_delete)\n",
        "\n",
        "    # Interpolate missing values\n",
        "    df[' Total Flow vehicles less than 5.2m'] = df[' Total Flow vehicles less than 5.2m'].interpolate(method='linear')\n",
        "    df[' Total Flow vehicles 5.21m - 6.6m'] = df[' Total Flow vehicles 5.21m - 6.6m'].interpolate(method='linear')\n",
        "    df[' Total Flow vehicles 6.61m - 11.6m'] = df[' Total Flow vehicles 6.61m - 11.6m'].interpolate(method='linear')\n",
        "    df[' Total Flow vehicles above 11.6m'] = df[' Total Flow vehicles above 11.6m'].interpolate(method='linear')\n",
        "    df[' Speed Value'] = df[' Speed Value'].interpolate(method='linear')\n",
        "\n",
        "    # Perform the multiplications and renaming\n",
        "    df['Category 1'] = df[' Total Flow vehicles less than 5.2m'] * 1\n",
        "    df['Category 2'] = df[' Total Flow vehicles 5.21m - 6.6m'] * 1.5\n",
        "    df['Category 3'] = df[' Total Flow vehicles 6.61m - 11.6m'] * 2\n",
        "    df['Category 4'] = df[' Total Flow vehicles above 11.6m'] * 2.3\n",
        "    df['Avg Speed in mph'] = df[' Speed Value'] * 0.621371\n",
        "\n",
        "    # Drop the original columns that have been transformed\n",
        "    df = df.drop(columns=[' Total Flow vehicles less than 5.2m',\n",
        "                          ' Total Flow vehicles 5.21m - 6.6m',\n",
        "                          ' Total Flow vehicles 6.61m - 11.6m',\n",
        "                          ' Total Flow vehicles above 11.6m',\n",
        "                          ' Speed Value'])\n",
        "\n",
        "    # Add the new column for total number of vehicles\n",
        "    df['Total number of vehicles'] = df['Category 1'] + df['Category 2'] + df['Category 3'] + df['Category 4']\n",
        "\n",
        "    # Group the data in 4-row chunks and sum the values\n",
        "    def aggregate_chunk(chunk):\n",
        "        return pd.Series({\n",
        "            'Local Date': chunk['Local Date'].iloc[0],\n",
        "            ' Local Time': chunk[' Local Time'].iloc[0][:2] + ':00:00',\n",
        "            'Category 1': chunk['Category 1'].sum(),\n",
        "            'Category 2': chunk['Category 2'].sum(),\n",
        "            'Category 3': chunk['Category 3'].sum(),\n",
        "            'Category 4': chunk['Category 4'].sum(),\n",
        "            'Avg Speed in mph': chunk['Avg Speed in mph'].mean(),  # Assuming average speed is desired\n",
        "            'Total number of vehicles': chunk['Total number of vehicles'].sum()\n",
        "        })\n",
        "\n",
        "    # Apply the aggregation function to each 4-row chunk\n",
        "    aggregated_df = df.groupby(df.index // 4).apply(aggregate_chunk).reset_index(drop=True)\n",
        "\n",
        "    # Round the Total number of vehicles to the nearest integer\n",
        "    aggregated_df['Total number of vehicles'] = aggregated_df['Total number of vehicles'].round()\n",
        "    aggregated_df['LOS'] = aggregated_df['Total number of vehicles'] / aggregated_df['Avg Speed in mph']\n",
        "\n",
        "    # Categorize LOS values\n",
        "    los_bins = [0, 11, 18, 26, 35, 40, float('inf')]\n",
        "    los_labels = ['A', 'B', 'C', 'D', 'E', 'F']\n",
        "    aggregated_df['LOS Category'] = pd.cut(aggregated_df['LOS'], bins=los_bins, labels=los_labels, right=False)\n",
        "\n",
        "    # Ensure uniqueness by combining 'Local Date' and ' Local Time'\n",
        "    aggregated_df['DateTime'] = aggregated_df['Local Date'] + ' ' + aggregated_df[' Local Time']\n",
        "\n",
        "    # Handle duplicates by aggregating\n",
        "    aggregated_df = aggregated_df.groupby('DateTime').agg({\n",
        "        'Category 1': 'sum',\n",
        "        'Category 2': 'sum',\n",
        "        'Category 3': 'sum',\n",
        "        'Category 4': 'sum',\n",
        "        'Avg Speed in mph': 'mean',\n",
        "        'Total number of vehicles': 'sum',\n",
        "        'LOS': 'mean',\n",
        "        'LOS Category': lambda x: x.mode()[0]  # Use mode for LOS Category\n",
        "    }).reset_index()\n",
        "\n",
        "    # Pivot the DataFrame\n",
        "    df_pivot = aggregated_df.pivot(index='DateTime', columns='LOS Category', values='LOS')\n",
        "\n",
        "    # Count values for each LOS category\n",
        "    los_category_counts = aggregated_df['LOS Category'].value_counts().reindex(los_labels, fill_value=0)\n",
        "\n",
        "    # Save the aggregated DataFrame to a new CSV file\n",
        "    df_pivot.to_csv(output_csv_file_path, index=True)\n",
        "\n",
        "    print(f\"Aggregated data saved to '{output_csv_file_path}'\")\n",
        "    print(\"LOS Category Counts:\")\n",
        "    print(los_category_counts)\n",
        "\n",
        "    total_los_counts = los_category_counts.sum()\n",
        "    pa = los_category_counts['A'] / total_los_counts\n",
        "    pb = los_category_counts['B'] / total_los_counts\n",
        "    pc = los_category_counts['C'] / total_los_counts\n",
        "    pd = los_category_counts['D'] / total_los_counts\n",
        "    pe = los_category_counts['E'] / total_los_counts\n",
        "    pf = los_category_counts['F'] / total_los_counts\n",
        "\n",
        "    print(f'Proportions: A: {pa}, B: {pb}, C: {pc}, D: {pd}, E: {pe}, F: {pf}')\n",
        "except pd.errors.ParserError as e:\n",
        "    print(f'ParserError: {e}')\n",
        "except Exception as e:\n",
        "    print(f'Error: {e}')\n"
      ],
      "metadata": {
        "id": "sj3WK4-YHRpn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5af66c23-a1a6-4824-ae4d-f106ee5ad2ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: \"['Day Type ID', 'Total Carriageway Flow', 'Quality Index', 'Network Link Id', 'NTIS Model Version'] not found in axis\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the Excel file\n",
        "df = pd.read_excel('Westbound.xlsx')\n",
        "\n",
        "# Count the occurrences of A, B, C, D, and E\n",
        "counts = df.apply(pd.Series.value_counts).sum(axis=1)\n",
        "\n",
        "# Calculate the total count\n",
        "total_count = counts.sum()\n",
        "\n",
        "# Calculate the proportions for each character\n",
        "pa = counts.get('A', 0) / total_count\n",
        "pb = counts.get('B', 0) / total_count\n",
        "pc = counts.get('C', 0) / total_count\n",
        "pd = counts.get('D', 0) / total_count\n",
        "pe = counts.get('E', 0) / total_count\n",
        "\n",
        "# Print the results\n",
        "print(\"Counts:\")\n",
        "print(counts)\n",
        "print(\"\\nProportions:\")\n",
        "print(f\"Proportion of A: {pa:.4f}\")\n",
        "print(f\"Proportion of B: {pb:.4f}\")\n",
        "print(f\"Proportion of C: {pc:.4f}\")\n",
        "print(f\"Proportion of D: {pd:.4f}\")\n",
        "print(f\"Proportion of E: {pe:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_xVFDTPmZZj",
        "outputId": "38b8be15-b133-4cee-d5a6-f00fc99fab08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counts:\n",
            "A    1242.0\n",
            "B     721.0\n",
            "C     149.0\n",
            "dtype: float64\n",
            "\n",
            "Proportions:\n",
            "Proportion of A: 0.5881\n",
            "Proportion of B: 0.3414\n",
            "Proportion of C: 0.0705\n",
            "Proportion of D: 0.0000\n",
            "Proportion of E: 0.0000\n"
          ]
        }
      ]
    }
  ]
}